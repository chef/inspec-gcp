# frozen_string_literal: false

# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
#     Please read more about how to change this file in README.md and
#     CONTRIBUTING.md located at the root of this package.
#
# ----------------------------------------------------------------------------
require 'gcp_backend'
require 'google/vertexai/property/modeldeploymentmonitoringjob_bigquery_tables'
require 'google/vertexai/property/modeldeploymentmonitoringjob_encryption_spec'
require 'google/vertexai/property/modeldeploymentmonitoringjob_error'
require 'google/vertexai/property/modeldeploymentmonitoringjob_labels'
require 'google/vertexai/property/modeldeploymentmonitoringjob_latest_monitoring_pipeline_metadata'
require 'google/vertexai/property/modeldeploymentmonitoringjob_latest_monitoring_pipeline_metadata_status'
require 'google/vertexai/property/modeldeploymentmonitoringjob_logging_sampling_strategy'
require 'google/vertexai/property/modeldeploymentmonitoringjob_logging_sampling_strategy_random_sample_config'
require 'google/vertexai/property/modeldeploymentmonitoringjob_model_deployment_monitoring_objective_configs'
require 'google/vertexai/property/modeldeploymentmonitoringjob_model_deployment_monitoring_schedule_config'
require 'google/vertexai/property/modeldeploymentmonitoringjob_model_monitoring_alert_config'
require 'google/vertexai/property/modeldeploymentmonitoringjob_model_monitoring_alert_config_email_alert_config'
require 'google/vertexai/property/modeldeploymentmonitoringjob_stats_anomalies_base_directory'

# A provider to manage Vertex AI resources.
class VertexAIModelDeploymentMonitoringJob < GcpResourceBase
  name 'google_vertex_ai_model_deployment_monitoring_job'
  desc 'ModelDeploymentMonitoringJob'
  supports platform: 'gcp'

  attr_reader :params
  attr_reader :model_deployment_monitoring_objective_configs
  attr_reader :labels
  attr_reader :state
  attr_reader :analysis_instance_schema_uri
  attr_reader :enable_monitoring_pipeline_logs
  attr_reader :endpoint
  attr_reader :logging_sampling_strategy
  attr_reader :bigquery_tables
  attr_reader :display_name
  attr_reader :schedule_state
  attr_reader :error
  attr_reader :model_monitoring_alert_config
  attr_reader :latest_monitoring_pipeline_metadata
  attr_reader :sample_predict_instance
  attr_reader :predict_instance_schema_uri
  attr_reader :next_schedule_time
  attr_reader :create_time
  attr_reader :log_ttl
  attr_reader :stats_anomalies_base_directory
  attr_reader :update_time
  attr_reader :model_deployment_monitoring_schedule_config
  attr_reader :encryption_spec
  attr_reader :name

  def initialize(params)
    super(params.merge({ use_http_transport: true }))
    @params = params
    @fetched = @connection.fetch(product_url(params[:beta]), resource_base_url, params, 'Get')
    parse unless @fetched.nil?
  end

  def parse
    @model_deployment_monitoring_objective_configs = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobModelDeploymentMonitoringObjectiveConfigsArray.parse(@fetched['modelDeploymentMonitoringObjectiveConfigs'], to_s)
    @labels = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobLabels.new(@fetched['labels'], to_s)
    @state = @fetched['state']
    @analysis_instance_schema_uri = @fetched['analysisInstanceSchemaUri']
    @enable_monitoring_pipeline_logs = @fetched['enableMonitoringPipelineLogs']
    @endpoint = @fetched['endpoint']
    @logging_sampling_strategy = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobLoggingSamplingStrategy.new(@fetched['loggingSamplingStrategy'], to_s)
    @bigquery_tables = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobBigqueryTablesArray.parse(@fetched['bigqueryTables'], to_s)
    @display_name = @fetched['displayName']
    @schedule_state = @fetched['scheduleState']
    @error = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobError.new(@fetched['error'], to_s)
    @model_monitoring_alert_config = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobModelMonitoringAlertConfig.new(@fetched['modelMonitoringAlertConfig'], to_s)
    @latest_monitoring_pipeline_metadata = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobLatestMonitoringPipelineMetadata.new(@fetched['latestMonitoringPipelineMetadata'], to_s)
    @sample_predict_instance = @fetched['samplePredictInstance']
    @predict_instance_schema_uri = @fetched['predictInstanceSchemaUri']
    @next_schedule_time = @fetched['nextScheduleTime']
    @create_time = @fetched['createTime']
    @log_ttl = @fetched['logTtl']
    @stats_anomalies_base_directory = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobStatsAnomaliesBaseDirectory.new(@fetched['statsAnomaliesBaseDirectory'], to_s)
    @update_time = @fetched['updateTime']
    @model_deployment_monitoring_schedule_config = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobModelDeploymentMonitoringScheduleConfig.new(@fetched['modelDeploymentMonitoringScheduleConfig'], to_s)
    @encryption_spec = GoogleInSpec::VertexAI::Property::ModelDeploymentMonitoringJobEncryptionSpec.new(@fetched['encryptionSpec'], to_s)
    @name = @fetched['name']
  end

  def exists?
    !@fetched.nil?
  end

  def to_s
    "ModelDeploymentMonitoringJob #{@params[:name]}"
  end

  private

  def product_url(_ = nil)
    'https://{{region}}-aiplatform.googleapis.com/v1/'
  end

  def resource_base_url
    '{{name}}'
  end
end
